{
  "hash": "19991c28dc34ee9a85a49da88143b4db",
  "result": {
    "engine": "knitr",
    "markdown": "# Shell Scripting {#sec-shell-scripting}\n\n\n\n::: {.callout-note title=\"Learning Objectives\"}\nAfter completing this chapter, you will be able to:\n\n- Create and execute shell scripts\n- Use variables, arrays, and command substitution\n- Write conditional statements and loops\n- Define and call functions\n- Handle command-line arguments\n- Implement proper error handling\n- Build reproducible analysis pipelines\n:::\n\n## Why Shell Scripting? {#sec-why-shell-scripting}\n\nThroughout the previous chapters, you've been typing commands interactively. While this is great for exploration, real-world analyses require something more [@sandve2013ten]:\n\n- **Reproducibility**: Record exactly what you did\n- **Automation**: Run the same analysis on many files\n- **Efficiency**: Avoid repetitive typing\n- **Documentation**: Explain why you did each step\n- **Sharing**: Let others reproduce your work\n\nShell scripts transform a series of commands into a reusable, documented program.\n\n## Your First Shell Script {#sec-first-script}\n\nA shell script is simply a text file containing commands. Let's create one:\n\n```bash\n#!/bin/bash\n# first_script.sh - My first shell script\n# Author: Your Name\n# Date: 2025-01-15\n\n# Display a greeting\necho \"Hello, Bioengineering!\"\n\n# Show the current date\necho \"Today is: $(date +%Y-%m-%d)\"\n\n# List files in current directory\necho \"Files in this directory:\"\nls -la\n```\n\n### The Shebang Line\n\nThe first line `#!/bin/bash` is called a **shebang** (or hashbang). It tells the operating system which interpreter should execute this script. Always include it.\n\nOther common shebangs:\n\n- `#!/bin/bash` — Bash shell (most common)\n- `#!/bin/sh` — POSIX shell (more portable)\n- `#!/usr/bin/env python3` — Python 3\n- `#!/usr/bin/env Rscript` — R\n\n### Running Scripts\n\nThere are several ways to run a script:\n\n```bash\n# Method 1: Invoke the interpreter explicitly\n$ bash first_script.sh\n\n# Method 2: Make executable and run directly\n$ chmod +x first_script.sh\n$ ./first_script.sh\n```\n\nThe `chmod +x` command adds execute permission to the file. After that, you can run it directly with `./`. The `./` is necessary because your current directory typically isn't in your system's PATH.\n\n::: {.callout-tip}\nAlways use `chmod +x` on your scripts. It signals that the file is meant to be executed and allows direct invocation.\n:::\n\n## Variables {#sec-shell-variables}\n\nVariables store values for later use. In Bash, variable assignment has strict syntax rules.\n\n### Assigning Variables\n\n```bash\n#!/bin/bash\n\n# Assign variables (NO spaces around the =)\nNAME=\"DNA Analysis\"\nCOUNT=100\nINPUT_FILE=\"sequences.fa\"\n\n# Use variables (with $ prefix)\necho \"Running $NAME\"\necho \"Processing $COUNT sequences from $INPUT_FILE\"\n\n# Curly braces for clarity\necho \"File: ${INPUT_FILE}\"\necho \"Creating ${INPUT_FILE}.backup\"\n```\n\n::: {.callout-warning title=\"Common Mistake\"}\nSpaces around `=` will cause errors!\n\n```bash\n# WRONG - causes errors\nNAME = \"value\"\nCOUNT= 100\n\n# RIGHT - no spaces\nNAME=\"value\"\nCOUNT=100\n```\n:::\n\n### Command Substitution\n\nCapture command output in a variable:\n\n```bash\n#!/bin/bash\n\n# Old syntax (backticks)\nTODAY=`date +%Y-%m-%d`\n\n# Modern syntax (preferred)\nTODAY=$(date +%Y-%m-%d)\nFILECOUNT=$(ls *.fa | wc -l)\nGENOME_SIZE=$(grep -v \"^>\" genome.fa | tr -d '\\n' | wc -c)\n\necho \"Analysis date: $TODAY\"\necho \"Processing $FILECOUNT FASTA files\"\necho \"Genome size: $GENOME_SIZE bp\"\n```\n\n### Arithmetic Operations\n\nBash arithmetic uses `$(( ))`:\n\n```bash\n#!/bin/bash\n\nCOUNT=10\nDOUBLE=$((COUNT * 2))\nINCREMENT=$((COUNT + 1))\n\n# Calculate percentage\nTOTAL=1000\nMATCHED=350\nPERCENT=$((MATCHED * 100 / TOTAL))\n\necho \"Doubled: $DOUBLE\"\necho \"Match rate: $PERCENT%\"\n```\n\nFor floating-point math, use external tools like `bc`:\n\n```bash\nGC_CONTENT=$(echo \"scale=2; 450 / 1000 * 100\" | bc)\necho \"GC content: $GC_CONTENT%\"\n```\n\n### String Operations\n\n```bash\n#!/bin/bash\n\nFILE=\"sample_001.fastq.gz\"\n\n# Remove suffix\nNAME=\"${FILE%.fastq.gz}\"    # sample_001\n\n# Remove prefix  \nNUMBER=\"${FILE#sample_}\"    # 001.fastq.gz\n\n# Remove longest match from end\nBASENAME=\"${FILE%%.*}\"      # sample_001\n\n# String length\nLENGTH=${#FILE}             # 19\n\necho \"Original: $FILE\"\necho \"Name without extension: $NAME\"\necho \"Length: $LENGTH characters\"\n```\n\n## Arrays {#sec-shell-arrays}\n\nArrays store multiple values:\n\n```bash\n#!/bin/bash\n\n# Declare an array\nBASES=(A C G T)\nSAMPLES=(\"control\" \"treatment_1\" \"treatment_2\")\n\n# Access elements (0-indexed)\necho \"First base: ${BASES[0]}\"        # A\necho \"Second sample: ${SAMPLES[1]}\"   # treatment_1\n\n# All elements\necho \"All bases: ${BASES[@]}\"\n\n# Array length\necho \"Number of samples: ${#SAMPLES[@]}\"\n\n# Add element\nBASES+=(N)\n\n# Loop through array\nfor sample in \"${SAMPLES[@]}\"; do\n    echo \"Processing: $sample\"\ndone\n```\n\n## Conditional Statements {#sec-shell-conditionals}\n\nConditionals control program flow based on tests.\n\n### Basic if/then/else\n\n```bash\n#!/bin/bash\n\nCOUNT=100\n\nif [ $COUNT -gt 50 ]; then\n    echo \"High count\"\nelif [ $COUNT -gt 10 ]; then\n    echo \"Medium count\"\nelse\n    echo \"Low count\"\nfi\n```\n\n### Test Operators\n\n**Numeric comparisons:**\n\n| Operator | Meaning |\n|:---------|:--------|\n| `-eq` | Equal |\n| `-ne` | Not equal |\n| `-gt` | Greater than |\n| `-ge` | Greater than or equal |\n| `-lt` | Less than |\n| `-le` | Less than or equal |\n\n**String comparisons:**\n\n| Operator | Meaning |\n|:---------|:--------|\n| `=` | Equal |\n| `!=` | Not equal |\n| `-z` | Zero length (empty) |\n| `-n` | Non-zero length |\n\n**File tests:**\n\n| Operator | Meaning |\n|:---------|:--------|\n| `-f` | File exists and is regular file |\n| `-d` | Directory exists |\n| `-e` | File exists (any type) |\n| `-r` | File is readable |\n| `-w` | File is writable |\n| `-x` | File is executable |\n| `-s` | File exists and is not empty |\n\n### Examples\n\n```bash\n#!/bin/bash\n\n# File existence check\nif [ -f \"data.txt\" ]; then\n    echo \"File exists\"\nelse\n    echo \"File not found\"\nfi\n\n# Directory check with creation\nif [ ! -d \"results\" ]; then\n    mkdir results\n    echo \"Created results directory\"\nfi\n\n# String comparison\nFILETYPE=\"fasta\"\nif [ \"$FILETYPE\" = \"fasta\" ]; then\n    echo \"Processing FASTA file\"\nfi\n\n# Combining conditions\nif [ -f \"$FILE\" ] && [ -r \"$FILE\" ]; then\n    echo \"File exists and is readable\"\nfi\n```\n\n::: {.callout-important}\nAlways quote variables in tests: `[ \"$VAR\" = \"value\" ]`. Without quotes, empty variables cause syntax errors.\n:::\n\n## Loops {#sec-shell-loops}\n\nLoops repeat actions multiple times.\n\n### For Loops\n\n```bash\n#!/bin/bash\n\n# Loop over a list\nfor base in A C G T; do\n    echo \"Base: $base\"\ndone\n\n# Loop over files\nfor file in *.fastq; do\n    echo \"Processing: $file\"\n    gzip \"$file\"\ndone\n\n# Loop with counter\nfor i in {1..10}; do\n    echo \"Iteration $i\"\ndone\n\n# C-style loop\nfor ((i=0; i<10; i++)); do\n    echo \"Index: $i\"\ndone\n\n# Loop over array\nFILES=(\"sample1.fa\" \"sample2.fa\" \"sample3.fa\")\nfor file in \"${FILES[@]}\"; do\n    echo \"Analyzing $file\"\ndone\n```\n\n### While Loops\n\n```bash\n#!/bin/bash\n\n# Count down\nCOUNT=5\nwhile [ $COUNT -gt 0 ]; do\n    echo \"Count: $COUNT\"\n    COUNT=$((COUNT - 1))\ndone\n\n# Read file line by line\nwhile read line; do\n    echo \"Processing: $line\"\ndone < input.txt\n\n# Process command output\nls *.fa | while read file; do\n    echo \"Found: $file\"\ndone\n```\n\n### Loop Control\n\n```bash\n#!/bin/bash\n\nfor file in *.fa; do\n    # Skip files starting with \"test\"\n    if [[ \"$file\" == test* ]]; then\n        continue\n    fi\n    \n    # Stop if we find \"final.fa\"\n    if [ \"$file\" = \"final.fa\" ]; then\n        echo \"Found final file, stopping\"\n        break\n    fi\n    \n    echo \"Processing: $file\"\ndone\n```\n\n## Command-Line Arguments {#sec-cli-arguments}\n\nScripts become more flexible when they accept arguments:\n\n```bash\n#!/bin/bash\n# process_fasta.sh - Process a FASTA file\n\n# $0 is the script name\necho \"Script: $0\"\n\n# $# is the number of arguments\necho \"Arguments received: $#\"\n\n# $1, $2, etc. are positional arguments\nINPUT=$1\nOUTPUT=$2\n\n# $@ is all arguments\necho \"All arguments: $@\"\n\n# Check for required arguments\nif [ $# -lt 2 ]; then\n    echo \"Usage: $0 input.fasta output.txt\"\n    exit 1\nfi\n\n# Now process the files\necho \"Input: $INPUT\"\necho \"Output: $OUTPUT\"\n```\n\nUsage:\n```bash\n$ ./process_fasta.sh sequences.fa results.txt\n```\n\n### Argument Validation\n\n```bash\n#!/bin/bash\n\n# Check argument count\nif [ $# -ne 2 ]; then\n    echo \"Error: Expected 2 arguments, got $#\" >&2\n    echo \"Usage: $0 input.fa output.txt\" >&2\n    exit 1\nfi\n\nINPUT=$1\nOUTPUT=$2\n\n# Validate input file\nif [ ! -f \"$INPUT\" ]; then\n    echo \"Error: Input file '$INPUT' not found\" >&2\n    exit 1\nfi\n\n# Check if output would overwrite\nif [ -f \"$OUTPUT\" ]; then\n    echo \"Warning: Output file exists. Overwrite? (y/n)\"\n    read answer\n    if [ \"$answer\" != \"y\" ]; then\n        exit 0\n    fi\nfi\n\n# Continue with processing...\n```\n\n## Functions {#sec-shell-functions}\n\nFunctions make scripts modular and reusable:\n\n```bash\n#!/bin/bash\n\n# Define a function\ncount_sequences() {\n    local FILE=$1  # Local variable\n    local COUNT=$(grep -c \"^>\" \"$FILE\")\n    echo $COUNT\n}\n\n# Function with multiple parameters\nanalyze_fasta() {\n    local INPUT=$1\n    local OUTPUT=$2\n    \n    echo \"Analyzing $INPUT...\"\n    \n    local SEQ_COUNT=$(count_sequences \"$INPUT\")\n    local TOTAL_LENGTH=$(grep -v \"^>\" \"$INPUT\" | tr -d '\\n' | wc -c)\n    \n    echo \"Sequences: $SEQ_COUNT\" > \"$OUTPUT\"\n    echo \"Total bases: $TOTAL_LENGTH\" >> \"$OUTPUT\"\n}\n\n# Call functions\nSEQ_NUM=$(count_sequences \"proteins.fa\")\necho \"Found $SEQ_NUM sequences\"\n\nanalyze_fasta \"input.fa\" \"statistics.txt\"\n```\n\n### Return Values\n\nFunctions return exit status (0-255), not strings. To return data:\n\n```bash\n#!/bin/bash\n\n# Return via stdout\nget_gc_content() {\n    local FILE=$1\n    local GC=$(grep -v \"^>\" \"$FILE\" | tr -d '\\n' | grep -o \"[GC]\" | wc -l)\n    local TOTAL=$(grep -v \"^>\" \"$FILE\" | tr -d '\\n' | wc -c)\n    echo \"$((GC * 100 / TOTAL))\"\n}\n\n# Capture output\nGC_PERCENT=$(get_gc_content \"genome.fa\")\necho \"GC content: $GC_PERCENT%\"\n\n# Return status for success/failure\ncheck_file() {\n    if [ -f \"$1\" ] && [ -r \"$1\" ]; then\n        return 0  # Success\n    else\n        return 1  # Failure\n    fi\n}\n\nif check_file \"data.txt\"; then\n    echo \"File is ready\"\nelse\n    echo \"File not accessible\"\nfi\n```\n\n## Error Handling {#sec-error-handling}\n\nRobust scripts handle errors gracefully.\n\n### Exit Status\n\nEvery command returns an exit status: 0 for success, non-zero for failure.\n\n```bash\n#!/bin/bash\n\n# Check last command's status\ngrep \"pattern\" file.txt\nif [ $? -ne 0 ]; then\n    echo \"Pattern not found\"\nfi\n\n# Conditional execution\ngrep \"pattern\" file.txt && echo \"Found!\"\ngrep \"pattern\" file.txt || echo \"Not found\"\n```\n\n### Strict Mode\n\nStart scripts with these settings for better error detection:\n\n```bash\n#!/bin/bash\nset -e          # Exit on any error\nset -u          # Error on undefined variables\nset -o pipefail # Catch errors in pipes\n\n# Or combine: set -euo pipefail\n```\n\n### Custom Error Handling\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\n# Define error handler\nerror_exit() {\n    echo \"Error on line $1\" >&2\n    exit 1\n}\n\n# Set trap to call handler on error\ntrap 'error_exit $LINENO' ERR\n\n# Now errors are caught\ncheck_file() {\n    if [ ! -f \"$1\" ]; then\n        echo \"Error: File $1 not found!\" >&2\n        exit 1\n    fi\n}\n\n# Validate inputs\ncheck_file \"$1\"\n\n# Continue processing...\n```\n\n### Cleanup on Exit\n\nEnsure temporary files are removed even if script fails:\n\n```bash\n#!/bin/bash\n\n# Create temp file\nTMPFILE=$(mktemp)\n\n# Remove temp file on exit (normal or error)\ntrap \"rm -f $TMPFILE\" EXIT\n\n# Use temp file...\necho \"working data\" > \"$TMPFILE\"\n# ... do processing ...\n\n# Cleanup happens automatically\n```\n\n## Running R Scripts from the Shell {#sec-rscript}\n\nWhile shell scripts are powerful, sometimes you need R's statistical capabilities. The `Rscript` command lets you run R code directly from the shell.\n\n### Basic Usage\n\n```bash\n# Run an R script\n$ Rscript my_analysis.R\n\n# Execute a single R expression\n$ Rscript -e \"print('Hello from R!')\"\n\n# Quick calculation\n$ Rscript -e \"mean(c(1, 2, 3, 4, 5))\"\n```\n\n### Passing Arguments to R Scripts\n\nYou can pass command-line arguments to R scripts, making them flexible and reusable:\n\n```r\n#!/usr/bin/env Rscript\n# process_data.R - Process a data file with custom parameters\n\n# Capture command-line arguments\nargs <- commandArgs(trailingOnly = TRUE)\n\n# Check for required arguments\nif (length(args) < 2) {\n  stop(\"Usage: Rscript process_data.R <input_file> <output_file>\")\n}\n\ninput_file <- args[1]\noutput_file <- args[2]\n\n# Now use these in your analysis\ndata <- read.csv(input_file)\n# ... process data ...\nwrite.csv(data, output_file)\n\ncat(\"Processed\", input_file, \"-> \", output_file, \"\\n\")\n```\n\nRun it from the shell:\n\n```bash\n$ Rscript process_data.R raw_data.csv cleaned_data.csv\n```\n\n### Combining Shell and R\n\nA common pattern is using shell scripts to orchestrate R analyses:\n\n```bash\n#!/bin/bash\n# run_analysis.sh - Process all CSV files in a directory\n\nfor file in data/*.csv; do\n    output=\"results/$(basename \"$file\" .csv)_processed.csv\"\n    echo \"Processing $file...\"\n    Rscript process_data.R \"$file\" \"$output\"\ndone\n\necho \"All files processed!\"\n```\n\n::: {.callout-tip}\nUsing `Rscript` is particularly valuable for batch processing, scheduled tasks (cron jobs), and integration with high-performance computing clusters where you submit shell scripts as jobs.\n:::\n\n## A Complete Bioinformatics Script {#sec-complete-script}\n\nLet's put it all together with a realistic example:\n\n```bash\n#!/bin/bash\n#===============================================================================\n# fasta_stats.sh - Calculate statistics for FASTA files\n# \n# Usage: ./fasta_stats.sh input.fasta [output.txt]\n#\n# Author: Your Name\n# Date: 2025-01-15\n#===============================================================================\n\nset -euo pipefail\n\n#-------------------------------------------------------------------------------\n# Configuration\n#-------------------------------------------------------------------------------\nVERSION=\"1.0.0\"\n\n#-------------------------------------------------------------------------------\n# Functions\n#-------------------------------------------------------------------------------\n\nusage() {\n    cat << EOF\nUsage: $(basename \"$0\") [OPTIONS] input.fasta [output.txt]\n\nCalculate basic statistics for FASTA files.\n\nOptions:\n    -h, --help      Show this help message\n    -v, --version   Show version information\n    -q, --quiet     Suppress progress messages\n\nArguments:\n    input.fasta     Input FASTA file (required)\n    output.txt      Output file (optional, defaults to stdout)\n\nExamples:\n    $(basename \"$0\") sequences.fa\n    $(basename \"$0\") genome.fa stats.txt\n    $(basename \"$0\") -q input.fa > results.txt\nEOF\n}\n\nlog() {\n    if [ \"$QUIET\" = false ]; then\n        echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" >&2\n    fi\n}\n\nerror() {\n    echo \"Error: $1\" >&2\n    exit 1\n}\n\ncount_sequences() {\n    grep -c \"^>\" \"$1\"\n}\n\ntotal_length() {\n    grep -v \"^>\" \"$1\" | tr -d '\\n' | wc -c | tr -d ' '\n}\n\ngc_content() {\n    local gc=$(grep -v \"^>\" \"$1\" | tr -d '\\n' | grep -o \"[GC]\" | wc -l | tr -d ' ')\n    local total=$(total_length \"$1\")\n    if [ \"$total\" -gt 0 ]; then\n        echo \"$((gc * 100 / total))\"\n    else\n        echo \"0\"\n    fi\n}\n\n#-------------------------------------------------------------------------------\n# Parse Arguments\n#-------------------------------------------------------------------------------\n\nQUIET=false\n\nwhile [[ $# -gt 0 ]]; do\n    case $1 in\n        -h|--help)\n            usage\n            exit 0\n            ;;\n        -v|--version)\n            echo \"$(basename \"$0\") version $VERSION\"\n            exit 0\n            ;;\n        -q|--quiet)\n            QUIET=true\n            shift\n            ;;\n        -*)\n            error \"Unknown option: $1\"\n            ;;\n        *)\n            break\n            ;;\n    esac\ndone\n\n# Check required arguments\nif [ $# -lt 1 ]; then\n    usage >&2\n    exit 1\nfi\n\nINPUT=\"$1\"\nOUTPUT=\"${2:-/dev/stdout}\"\n\n#-------------------------------------------------------------------------------\n# Validate Input\n#-------------------------------------------------------------------------------\n\nif [ ! -f \"$INPUT\" ]; then\n    error \"Input file not found: $INPUT\"\nfi\n\nif [ ! -r \"$INPUT\" ]; then\n    error \"Cannot read input file: $INPUT\"\nfi\n\n#-------------------------------------------------------------------------------\n# Main Analysis\n#-------------------------------------------------------------------------------\n\nlog \"Starting analysis of $INPUT\"\n\nlog \"Counting sequences...\"\nSEQ_COUNT=$(count_sequences \"$INPUT\")\n\nlog \"Calculating total length...\"\nTOTAL_LEN=$(total_length \"$INPUT\")\n\nlog \"Computing GC content...\"\nGC_PCT=$(gc_content \"$INPUT\")\n\n# Calculate average length\nif [ \"$SEQ_COUNT\" -gt 0 ]; then\n    AVG_LEN=$((TOTAL_LEN / SEQ_COUNT))\nelse\n    AVG_LEN=0\nfi\n\n#-------------------------------------------------------------------------------\n# Output Results\n#-------------------------------------------------------------------------------\n\n{\n    echo \"=== FASTA Statistics ===\"\n    echo \"File: $INPUT\"\n    echo \"Date: $(date '+%Y-%m-%d %H:%M:%S')\"\n    echo \"\"\n    echo \"Number of sequences: $SEQ_COUNT\"\n    echo \"Total length: $TOTAL_LEN bp\"\n    echo \"Average length: $AVG_LEN bp\"\n    echo \"GC content: $GC_PCT%\"\n} > \"$OUTPUT\"\n\nlog \"Analysis complete. Results written to $OUTPUT\"\n```\n\n## Best Practices Summary {#sec-scripting-best-practices}\n\n::: {.callout-tip title=\"Shell Scripting Best Practices\"}\n1. **Always include a shebang**: `#!/bin/bash`\n2. **Use strict mode**: `set -euo pipefail`\n3. **Comment your code**: Explain what and why\n4. **Use meaningful names**: `SEQ_COUNT` not `SC`\n5. **Validate inputs**: Check files exist, arguments are provided\n6. **Handle errors**: Provide useful error messages\n7. **Make it portable**: Don't hardcode paths\n8. **Test incrementally**: Build and test piece by piece\n9. **Version control**: Track changes with git\n10. **Document usage**: Include help messages\n:::\n\n## Summary {#sec-scripting-summary}\n\nThis chapter covered shell scripting essentials:\n\n- Scripts are text files containing commands with a shebang line\n- Variables store values; arrays store multiple values\n- Conditionals (`if/elif/else`) control flow based on tests\n- Loops (`for`, `while`) repeat actions\n- Functions make code modular and reusable\n- Command-line arguments make scripts flexible\n- Error handling ensures robustness\n- Combining these elements creates powerful analysis pipelines\n\nShell scripting is a foundational skill for computational biology. Even as you learn other languages like R and Python, shell scripts remain invaluable for automation, file management, and orchestrating complex workflows.\n\n::: {.callout-tip}\nFor quick reference on Unix commands used in shell scripts, see @sec-appendix-unix.\n:::\n\n## Additional Reading {.unnumbered}\n\nTo advance your shell scripting skills:\n\n- **[Bash Guide for Beginners](https://tldp.org/LDP/Bash-Beginners-Guide/html/)** — A comprehensive introduction to Bash scripting\n- **[Advanced Bash-Scripting Guide](https://tldp.org/LDP/abs/html/)** — An in-depth exploration of shell scripting techniques\n- **[ShellCheck](https://www.shellcheck.net/)** — An online tool for finding bugs in your shell scripts\n- **\"Learning the bash Shell\"** by Cameron Newham — A thorough guide to Bash programming\n- **[Google Shell Style Guide](https://google.github.io/styleguide/shellguide.html)** — Best practices for writing maintainable scripts\n\nFor bioinformatics workflow development:\n\n- **[Snakemake](https://snakemake.readthedocs.io/)** — A workflow management system that builds on shell scripting concepts\n- **[Nextflow](https://www.nextflow.io/)** — A domain-specific language for data-driven pipelines\n- **[GNU Make Tutorial](https://www.gnu.org/software/make/manual/)** — Build automation that complements shell scripts\n\n## Exercises {.unnumbered}\n\n::: {.callout-tip title=\"Practice Exercises\"}\n**Exercise 1: Basic Script**\n\nCreate a script that:\n1. Accepts a directory as an argument\n2. Counts files of each type (.txt, .csv, .fa, etc.)\n3. Reports the results\n\n**Exercise 2: File Processing Loop**\n\nWrite a script that:\n1. Loops through all `.fastq` files in a directory\n2. Counts the number of reads in each (hint: lines/4 in FASTQ)\n3. Saves results to a summary file\n\n**Exercise 3: FASTA Validator**\n\nCreate a script that validates FASTA files:\n1. Check that every header line starts with `>`\n2. Check that sequence lines only contain valid characters\n3. Report any errors found\n\n**Exercise 4: Analysis Pipeline**\n\nBuild a complete analysis script that:\n1. Accepts input/output arguments with validation\n2. Downloads a bacterial genome if not present\n3. Calculates genome statistics\n4. Finds all occurrences of a user-specified motif\n5. Generates a summary report\n6. Includes proper error handling and logging\n:::\n",
    "supporting": [
      "06-shell-scripting_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}