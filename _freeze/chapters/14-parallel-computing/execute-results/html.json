{
  "hash": "b57655ba119b81d0e14af3304427c0dd",
  "result": {
    "engine": "knitr",
    "markdown": "# Parallel Computing in R {#sec-parallel-computing}\n\n\n\n::: {.callout-note title=\"Learning Objectives\"}\nAfter completing this chapter, you will be able to:\n\n- Understand when parallel computing provides performance benefits\n- Use the future ecosystem for parallel programming in R\n- Apply future_lapply() and future_map() for parallel iteration\n- Choose between forking and socket-based parallelization\n- Understand the differences between explicit and implicit parallelization\n- Avoid common pitfalls like resource competition\n- Debug functions and handle errors in parallel contexts\n- Cache results to avoid recomputation\n:::\n\n## Why Parallel Computing? {#sec-why-parallel}\n\nModern computers have multiple processor cores, but by default R only uses one. This means that when you run a computationally intensive analysis --- like bootstrapping, permutation tests, or processing thousands of samples --- most of your computer's power sits idle.\n\n**Parallel computing** lets you use all available cores simultaneously, potentially reducing computation time by a factor equal to your core count. A task that takes 8 hours on one core might take just 1 hour across 8 cores.\n\nIn biosciences, parallel computing is especially valuable for:\n\n- **Bootstrapping** for confidence intervals\n- **Permutation tests** for significance testing\n- **Simulation studies** (e.g., population genetics)\n- **Processing many samples** (e.g., analyzing hundreds of RNA-seq files)\n- **Cross-validation** in machine learning\n- **Parameter sweeps** for computational models\n\n## How Many Cores Do You Have? {#sec-cores}\n\nBefore parallelizing, find out how many cores are available:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparallel::detectCores()\n#> [1] 14\n```\n:::\n\n\nThis number includes both physical cores and \"logical\" cores (from technologies like Intel's hyperthreading). For CPU-intensive tasks, your effective speedup is typically limited by the number of physical cores.\n\n## A Motivating Example {#sec-parallel-example}\n\nLet's start with a simple example to demonstrate the power of parallelization. We'll create a deliberately slow function that simulates a computationally expensive operation:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Simulate analyzing a biological sample (takes 2 seconds each)\nanalyze_sample = function(sample_id) {\n  # Simulate processing time\n  Sys.sleep(2)\n\n  # Return some fake results\n  tibble(\n    sample_id = sample_id,\n    gene_count = sample(5000:20000, 1),\n    quality_score = runif(1, 0.8, 1.0)\n  )\n}\n```\n:::\n\n\n### Serial Execution\n\nFirst, let's process 8 samples the traditional way:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tictoc)\n\ntic()\nserial_results = lapply(1:8, analyze_sample) %>% bind_rows()\ntoc()\n#> 16.049 sec elapsed\n```\n:::\n\n\nAs expected, processing 8 samples at 2 seconds each takes about 16 seconds.\n\n### Parallel Execution\n\nNow let's do the same thing in parallel using the **future.apply** package:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(future.apply)\nplan(multisession)  # Enable parallel processing\n\ntic()\nparallel_results = future_lapply(1:8, analyze_sample) %>% bind_rows()\ntoc()\n#> 2.296 sec elapsed\n```\n:::\n\n\nThe parallel version is dramatically faster! With 8 cores, we can process all 8 samples simultaneously, reducing the time from ~16 seconds to ~2 seconds.\n\nLet's verify the results are identical:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Results have same structure (values differ due to random generation)\nall.equal(names(serial_results), names(parallel_results))\n#> [1] TRUE\n```\n:::\n\n\n## The Future Ecosystem {#sec-future}\n\nThe examples above use the **future** package ecosystem, which provides a unified, elegant approach to parallel programming in R. The key packages are:\n\n| Package | Description |\n|:--------|:------------|\n| **future** | Core package defining how code is evaluated |\n| **future.apply** | Parallel versions of apply functions |\n| **furrr** | Parallel versions of purrr functions |\n\n: The future ecosystem {#tbl-future-packages}\n\n### Setting Up Parallel Execution\n\nBefore running parallel code, you must set a \"plan\" that determines how futures are resolved:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(future)\n\n# Sequential (no parallelization - useful for debugging)\nplan(sequential)\n\n# Parallel using multiple R sessions (works on all systems)\nplan(multisession)\n\n# Parallel using forked processes (faster, but Unix/Mac only)\nplan(multicore)\n```\n:::\n\n\nFor most users, `plan(multisession)` is the safest choice as it works on all operating systems.\n\n### future_lapply: Parallel Apply\n\nThe `future_lapply()` function is a drop-in replacement for `lapply()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Serial version\n# lapply(1:4, function(x) x^2)\n\n# Parallel version - just add \"future_\"\nfuture_lapply(1:4, function(x) x^2)\n#> [[1]]\n#> [1] 1\n#> \n#> [[2]]\n#> [1] 4\n#> \n#> [[3]]\n#> [1] 9\n#> \n#> [[4]]\n#> [1] 16\n```\n:::\n\n\n### furrr: Parallel purrr\n\nIf you prefer **purrr**'s syntax, **furrr** provides parallel versions of all map functions:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(furrr)\n\n# Serial: map_dbl(1:4, function(x) x^2)\n# Parallel:\nfuture_map_dbl(1:4, function(x) x^2)\n#> [1]  1  4  9 16\n\n# Returns a data frame directly\nfuture_map_dfr(1:4, function(x) {\n  tibble(value = x, squared = x^2)\n})\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| value| squared|\n|-----:|-------:|\n|     1|       1|\n|     2|       4|\n|     3|       9|\n|     4|      16|\n\n</div>\n:::\n:::\n\n\n## A Real Example: Bootstrapping Gene Expression {#sec-bootstrap-example}\n\nLet's apply parallel computing to a realistic bioinformatics task: bootstrapping to estimate confidence intervals for differential expression.\n\n### Setup\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1234)\n\n# Simulate gene expression data for 1000 genes, 50 samples\nn_genes = 1000\nn_samples = 50\n\nexpression_data = tibble(\n  gene_id = rep(paste0(\"gene_\", 1:n_genes), each = n_samples),\n  sample_id = rep(paste0(\"sample_\", 1:n_samples), n_genes),\n  group = rep(rep(c(\"control\", \"treatment\"), each = n_samples/2), n_genes),\n  expression = rnorm(n_genes * n_samples, mean = 10, sd = 2)\n) %>%\n  # Add a treatment effect to some genes\n  mutate(\n    expression = if_else(\n      gene_id %in% paste0(\"gene_\", 1:100) & group == \"treatment\",\n      expression + rnorm(n(), 2, 0.5),  # Upregulated genes\n      expression\n    )\n  )\n\nhead(expression_data)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|gene_id |sample_id |group   | expression|\n|:-------|:---------|:-------|----------:|\n|gene_1  |sample_1  |control |   7.585869|\n|gene_1  |sample_2  |control |  10.554858|\n|gene_1  |sample_3  |control |  12.168882|\n|gene_1  |sample_4  |control |   5.308605|\n|gene_1  |sample_5  |control |  10.858249|\n|gene_1  |sample_6  |control |  11.012112|\n\n</div>\n:::\n:::\n\n\n### Bootstrap Function\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Function to bootstrap fold change for one gene\nbootstrap_fold_change = function(gene_data) {\n  # Resample within each group\n  boot_sample = gene_data %>%\n    group_by(group) %>%\n    slice_sample(prop = 1, replace = TRUE) %>%\n    ungroup()\n\n  # Calculate mean expression per group\n  means = boot_sample %>%\n    group_by(group) %>%\n    summarise(mean_expr = mean(expression), .groups = \"drop\")\n\n  # Calculate fold change (treatment / control)\n  fc = means$mean_expr[means$group == \"treatment\"] /\n       means$mean_expr[means$group == \"control\"]\n\n  return(fc)\n}\n\n# Function to run many bootstrap iterations for one gene\nrun_bootstrap = function(gene_id, data, n_boot = 1000) {\n  gene_data = data %>% filter(gene_id == !!gene_id)\n\n  # Run bootstrap iterations\n  boot_fcs = replicate(n_boot, bootstrap_fold_change(gene_data))\n\n  # Return summary statistics\n  tibble(\n    gene_id = gene_id,\n    mean_fc = mean(boot_fcs),\n    lower_ci = quantile(boot_fcs, 0.025),\n    upper_ci = quantile(boot_fcs, 0.975)\n  )\n}\n```\n:::\n\n\n### Compare Serial vs Parallel\n\nLet's bootstrap confidence intervals for 20 genes:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngenes_to_test = paste0(\"gene_\", 1:20)\n\n# Serial version\ntic()\nserial_boot = map_dfr(genes_to_test, run_bootstrap,\n                      data = expression_data, n_boot = 500)\ntoc()\n#> 16.204 sec elapsed\n\n# Parallel version\ntic()\nparallel_boot = future_map_dfr(genes_to_test, run_bootstrap,\n                                data = expression_data, n_boot = 500,\n                                .options = furrr_options(seed = TRUE))\ntoc()\n#> 2.95 sec elapsed\n```\n:::\n\n\nThe parallel version should be substantially faster, with speedup proportional to your core count.\n\n### View Results\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nparallel_boot %>%\n  mutate(\n    significant = lower_ci > 1 | upper_ci < 1,\n    direction = case_when(\n      lower_ci > 1 ~ \"upregulated\",\n      upper_ci < 1 ~ \"downregulated\",\n      TRUE ~ \"not significant\"\n    )\n  ) %>%\n  head(10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|gene_id |  mean_fc| lower_ci| upper_ci|significant |direction   |\n|:-------|--------:|--------:|--------:|:-----------|:-----------|\n|gene_1  | 1.131773| 1.024564| 1.238272|TRUE        |upregulated |\n|gene_2  | 1.172248| 1.048010| 1.295856|TRUE        |upregulated |\n|gene_3  | 1.186548| 1.088120| 1.289473|TRUE        |upregulated |\n|gene_4  | 1.183704| 1.054100| 1.320405|TRUE        |upregulated |\n|gene_5  | 1.127931| 1.012363| 1.237380|TRUE        |upregulated |\n|gene_6  | 1.131323| 1.031547| 1.240307|TRUE        |upregulated |\n|gene_7  | 1.176178| 1.069463| 1.302288|TRUE        |upregulated |\n|gene_8  | 1.178690| 1.031968| 1.313715|TRUE        |upregulated |\n|gene_9  | 1.273898| 1.166305| 1.398772|TRUE        |upregulated |\n|gene_10 | 1.265714| 1.126358| 1.420870|TRUE        |upregulated |\n\n</div>\n:::\n:::\n\n\n## Forking vs Sockets {#sec-fork-socket}\n\nThere are two main approaches to parallelization:\n\n### Socket-based (multisession)\n\n- Creates new R sessions for each worker\n- Works on **all operating systems** including Windows\n- Requires copying data to each worker (slower startup)\n- Selected with `plan(multisession)`\n\n### Fork-based (multicore)\n\n- Clones the current R session\n- Works on **Unix/Mac only** (not Windows)\n- Shares memory with parent process (faster)\n- Selected with `plan(multicore)`\n- May cause issues in RStudio; run from terminal for best results\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Safe choice for all systems\nplan(multisession)\n\n# Faster on Unix/Mac (run scripts from terminal)\nplan(multicore)\n\n# Specify number of workers\nplan(multisession, workers = 4)\n```\n:::\n\n\n::: {.callout-warning}\nOn Windows, `plan(multicore)` silently falls back to `plan(sequential)`. Always use `plan(multisession)` for cross-platform code.\n:::\n\n## Handling Errors in Parallel Code {#sec-parallel-errors}\n\nErrors in parallel code can be tricky to debug. The **purrr** package provides `safely()` and `possibly()` to handle errors gracefully:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# A function that sometimes fails\nrisky_analysis = function(x) {\n  if (x == 5) stop(\"Error processing sample 5!\")\n  tibble(sample = x, result = x^2)\n}\n\n# Wrap in safely() to catch errors\nsafe_analysis = safely(risky_analysis, otherwise = NULL)\n\n# Run in parallel - won't crash if one fails\nresults = future_map(1:10, safe_analysis)\n\n# Extract successful results\nsuccessful = map(results, \"result\") %>%\n  compact() %>%  # Remove NULLs\n\n  bind_rows()\n\n# See which failed\nerrors = map(results, \"error\") %>%\n  compact()\n\ncat(\"Successful:\", nrow(successful), \"\\n\")\n#> Successful: 9\ncat(\"Failed:\", length(errors), \"\\n\")\n#> Failed: 1\n```\n:::\n\n\nFor simpler error handling, use `possibly()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Returns NA for failed cases\nrobust_analysis = possibly(risky_analysis, otherwise = tibble(sample = NA, result = NA))\n\nfuture_map_dfr(1:10, robust_analysis)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| sample| result|\n|------:|------:|\n|      1|      1|\n|      2|      4|\n|      3|      9|\n|      4|     16|\n|     NA|     NA|\n|      6|     36|\n|      7|     49|\n|      8|     64|\n|      9|     81|\n|     10|    100|\n\n</div>\n:::\n:::\n\n\n## Caching Results {#sec-caching}\n\nFor expensive computations, cache intermediate results so you don't have to recompute them:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(memoise)\n\n# Create a slow function\nslow_gc_analysis = function(sequence) {\n  Sys.sleep(1)  # Simulate slow computation\n  tibble(\n    sequence = sequence,\n    gc_content = str_count(toupper(sequence), \"[GC]\") / nchar(sequence)\n  )\n}\n\n# Create memoised version\nmemo_gc_analysis = memoise(slow_gc_analysis)\n\n# First call - slow\ntic()\nresult1 = memo_gc_analysis(\"ATGCGATCGATCG\")\ntoc()\n#> 1.014 sec elapsed\n\n# Second call with same input - instant (cached)\ntic()\nresult2 = memo_gc_analysis(\"ATGCGATCGATCG\")\ntoc()\n#> 0.019 sec elapsed\n```\n:::\n\n\n### Persistent Caching\n\nTo cache results across R sessions (useful for long analyses):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create a cache directory\ncache_dir = \"analysis_cache\"\nif (!dir.exists(cache_dir)) dir.create(cache_dir)\n\n# Create memoised function with persistent cache\nmemo_gc_persistent = memoise(\n  slow_gc_analysis,\n  cache = cache_filesystem(cache_dir)\n)\n\n# Results will be saved to disk and available in future sessions\n```\n:::\n\n\n## When to Use Parallel Computing {#sec-when-parallel}\n\nParallel computing isn't always faster. Consider:\n\n### Good Candidates for Parallelization\n\n- **Independent iterations**: Each iteration doesn't depend on others\n- **CPU-intensive tasks**: Complex calculations, simulations\n- **Many iterations**: Overhead is amortized across many runs\n- **Long-running operations**: Minutes or hours of total computation\n\n### Poor Candidates\n\n- **Fast operations**: Overhead exceeds computation time\n- **Few iterations**: Not enough work to distribute\n- **Memory-intensive**: Each worker needs its own copy of data\n- **I/O bound**: Waiting for disk/network, not CPU\n\n### Amdahl's Law\n\nThe maximum speedup from parallelization is limited by the sequential portion of your code. If 50% of your code must run sequentially, you can never achieve more than 2Ã— speedup, regardless of core count.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14-parallel-computing_files/figure-html/amdahl-plot-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Best Practices {#sec-parallel-best-practices}\n\n### 1. Start Sequential, Then Parallelize\n\nAlways develop and debug your code in sequential mode first:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Debug with sequential execution\nplan(sequential)\n\n# Test with a small subset\ntest_results = map_dfr(1:3, my_analysis_function)\n\n# Once working, switch to parallel\nplan(multisession)\nfull_results = future_map_dfr(1:1000, my_analysis_function)\n```\n:::\n\n\n### 2. Set Random Seeds\n\nFor reproducible parallel simulations:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# future.apply\nfuture_lapply(1:10, my_function, future.seed = 123)\n\n# furrr\nfuture_map(1:10, my_function, .options = furrr_options(seed = 123))\n```\n:::\n\n\n### 3. Monitor Progress\n\nUse progress bars to track long-running parallel jobs:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(progressr)\n\nhandlers(\"txtprogressbar\")\n\nwith_progress({\n  p = progressor(steps = 100)\n\n  results = future_map(1:100, function(x) {\n    p()  # Signal progress\n    slow_function(x)\n  })\n})\n```\n:::\n\n\n### 4. Manage Memory\n\nEach parallel worker needs memory for:\n- A copy of R\n- Any data passed to the function\n- Results being computed\n\nIf you run out of memory, reduce the number of workers:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Use fewer workers for memory-intensive tasks\nplan(multisession, workers = 2)\n```\n:::\n\n\n## Summary {#sec-parallel-summary}\n\nParallel computing can dramatically speed up computationally intensive analyses:\n\n- The **future** ecosystem provides a simple, unified approach to parallelization\n- Use `plan(multisession)` for cross-platform compatibility\n- Replace `lapply()` with `future_lapply()` or `map()` with `future_map()`\n- Always develop in sequential mode first, then parallelize\n- Use `safely()` or `possibly()` to handle errors gracefully\n- Cache expensive results with **memoise** for persistent storage\n- Consider Amdahl's law: not everything benefits from parallelization\n\nParallel programming in R has never been easier. With just a few lines of code, you can harness all your computer's cores for faster, more efficient analyses.\n\n::: {.callout-tip}\nFor reference on R functions used in parallel computing workflows, see @sec-appendix-r.\n:::\n\n## Exercises {.unnumbered}\n\n::: {.callout-tip title=\"Practice Exercises\"}\n**Exercise 1: Basic Parallelization**\n\nWrite a function that simulates processing a biological sample (include a `Sys.sleep(1)` to simulate processing time). Use `future_lapply()` to process 10 samples in parallel and compare the time to serial execution.\n\n**Exercise 2: Bootstrap Analysis**\n\nUsing the gene expression simulation from this chapter:\n1. Write a function to bootstrap the mean expression of a single gene\n2. Apply it in parallel to 50 genes\n3. Calculate 95% confidence intervals for each gene\n\n**Exercise 3: Error Handling**\n\nCreate a function that analyzes DNA sequences but fails if the sequence contains invalid characters. Use `safely()` to process a list of sequences where some are invalid, and report which ones failed.\n\n**Exercise 4: Parameter Sweep**\n\nWrite a function that simulates bacterial growth with parameters for growth rate (k), carrying capacity (K), and initial population (n0). Use parallel computing to run simulations across a grid of parameter combinations.\n\n**Exercise 5: Caching**\n\nCreate a memoised version of a \"slow\" function that calculates protein properties. Demonstrate that repeated calls with the same input are instant.\n\n**Exercise 6: Benchmarking**\n\nFor a computationally intensive task of your choice:\n1. Time the serial version\n2. Time the parallel version with 2, 4, and 8 workers\n3. Calculate the speedup factor for each\n4. Does the speedup match what you'd expect from Amdahl's law?\n:::\n\n## Additional Reading {.unnumbered}\n\n- [future package documentation](https://future.futureverse.org/)\n- [furrr package documentation](https://furrr.futureverse.org/)\n- [Parallel Computing with R: A Brief Review](https://arxiv.org/abs/1912.11144) by Dirk Eddelbuettel\n- [R for Data Science: Iteration](https://r4ds.had.co.nz/iteration.html) chapter on functional programming\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}