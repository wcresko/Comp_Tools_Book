# Introduction to Computational Tools {#sec-introduction}

```{r}
#| label: setup
#| include: false
library(tidyverse)
library(gt)
theme_set(theme_minimal())
```

::: {.callout-note title="Learning Objectives"}
After completing this chapter, you will be able to:

- Articulate why computational skills are essential for modern bioscience research
- Distinguish between coding and scripting languages
- Identify the computational tools covered in this course
- Set up your computing environment for the course
:::

## The Computational Revolution in Biology

Modern biological research has undergone a profound transformation. The advent of high-throughput technologies—from next-generation sequencing to automated microscopy to mass spectrometry—has generated an explosion of data that far exceeds what can be analyzed manually. Consider these examples:

- A single human genome sequence contains approximately **6 billion base pairs**
- A typical RNA-seq experiment generates **tens of millions** of short reads
- Proteomics studies can identify and quantify **thousands of proteins** simultaneously
- High-content imaging screens produce **terabytes** of image data

To make sense of this data deluge, researchers must be fluent in computational tools. This fluency goes beyond simply running pre-made software—it requires understanding how to manipulate data, automate analyses, and ensure reproducibility.

## Why Learn Computational Skills?

There are compelling reasons to invest time in developing computational proficiency:

**Speed and Scale.** Computational tools allow you to perform thousands of operations with single commands. Tasks that would take days by hand can be completed in seconds.

**Reproducibility.** Scripts and code serve as a complete record of your analysis. Unlike clicking through graphical interfaces, command-line workflows can be exactly reproduced, shared, and verified [@sandve2013ten; @wilson2017good].

**Flexibility.** General-purpose programming languages can handle virtually any data format or analysis type. You're not limited to what software developers anticipated.

**Access to Specialized Tools.** Many cutting-edge analysis tools in bioinformatics are only available through the command line. Learning to use the shell opens doors to thousands of free programs developed by scientists for scientists.

**High-Performance Computing.** Large-scale analyses require computing clusters. These systems are accessed and controlled through command-line interfaces.

::: {.callout-tip title="Career Impact"}
Computational skills are increasingly valued in academic and industry positions. Investing in these skills now will pay dividends throughout your career. Organizing your computational projects well from the start saves countless hours later [@noble2009quick].
:::

## Coding vs. Scripting: What's the Difference?

You'll often hear the terms "coding" and "scripting" used interchangeably, but there are technical distinctions worth understanding.

### Compiled Languages (Coding)

**Compiled languages** require a separate compilation step that translates human-readable source code into machine code before execution. Examples include:

- C/C++
- Fortran
- Rust
- Go

The compilation process produces optimized executable files that run very quickly. However, compiled languages typically require more setup and are less forgiving of errors during development.

### Interpreted Languages (Scripting)

**Interpreted languages** (or scripting languages) execute code line-by-line at runtime, without a separate compilation step. Examples include:

- Bash/Shell
- Python
- R
- Julia
- Perl

Interpreted languages offer greater flexibility and faster development cycles at the cost of some execution speed. They're ideal for data analysis, automation, and interactive exploration.

::: {.callout-note}
The distinction between compiled and interpreted languages has become increasingly blurred. Modern systems like Julia use just-in-time (JIT) compilation to achieve near-compiled performance with scripting-language convenience. Python and R can also interface with compiled C/C++ code for performance-critical operations.
:::

### Which Should You Learn?

For most biological research, **interpreted languages are the right choice**. They enable rapid prototyping and experimentation—you can try an idea, see if it works, and refine it immediately. Their interactive nature makes them ideal for data exploration, allowing you to probe your data and understand its structure before committing to a particular analysis approach. The scientific computing community has developed extensive libraries for these languages, from statistical methods to machine learning to bioinformatics pipelines. And because interpreted languages tend to have more forgiving syntax and immediate feedback, they present lower barriers to entry for beginners.

In this course, we focus primarily on Bash (the Unix shell) and R, with exposure to high-performance computing concepts that may eventually lead you to compiled languages if your research requires it.

## Tools We Will Cover

This book and accompanying course introduce you to a carefully selected set of tools that form the foundation of computational research in the life sciences [@buffalo2015bioinformatics].

### Unix/Linux and the Shell

The **Unix shell** (specifically Bash) provides a powerful interface for file manipulation that goes far beyond what graphical file managers offer. It includes specialized tools for processing large text-based data files—essential when working with genomic sequences, tabular data, or log files. Perhaps most importantly, the shell lets you combine simple programs into complex workflows through pipes and scripting, and it provides access to remote computing systems using the same commands you use locally. Understanding Unix is essential because it underlies most scientific computing infrastructure, from laptops to supercomputers.

### R Statistical Programming

**R** is a programming language and environment specifically designed for statistical computing and graphics [@rproject2024]. It provides comprehensive statistical analysis capabilities, from basic descriptive statistics to advanced machine learning algorithms. R excels at producing publication-quality graphics with fine-grained control over every visual element. The community has developed thousands of packages for specialized analyses in virtually every domain of science, and R integrates seamlessly with reproducible document systems like Quarto and R Markdown. The RStudio IDE provides an excellent development environment that makes working with R accessible and productive.

### Quarto and Reproducible Documents

**Quarto** is an open-source scientific publishing system [@quarto2024] that enables you to combine narrative text with executable code in a single document. From this unified source, you can generate reports, presentations, websites, and books—all while ensuring your analyses are fully reproducible. Because the code runs when the document renders, results always match the code that produced them. You can then share your work in multiple formats (HTML, PDF, Word) without maintaining separate versions. This book itself was written using Quarto!

### Git and GitHub

**Git** is a version control system that tracks changes to your files over time [@chacon2014pro; @blischak2016practical]. **GitHub** is a web-based platform for hosting Git repositories. Together, they provide a complete history of your project's development, allowing you to understand how your work evolved and revert to earlier versions if needed. Git enables safe experimentation with new ideas through branching—you can try risky changes without affecting your working code. The platform facilitates collaboration with colleagues worldwide, letting multiple people work on the same project simultaneously. And GitHub makes it easy to share code and data publicly, contributing to open science and reproducible research.

### High-Performance Computing

**Talapas** is the University of Oregon's computing cluster. You'll learn to access and navigate this remote computing environment, submit and manage batch jobs that run when resources become available, use software modules to access specialized tools, and scale your analyses far beyond what your laptop can handle. When your analysis takes hours or days, or requires more memory than your personal computer has, Talapas provides the computational power you need.

## Setting Up Your Computing Environment

Before diving into the technical content, you'll need to set up your computing environment. The required software depends on your operating system.

### All Operating Systems

These tools work across Windows, macOS, and Linux:

1. **R** — Download from [r-project.org](https://www.r-project.org)
2. **RStudio** — Download from [posit.co/download/rstudio-desktop](https://posit.co/download/rstudio-desktop/)
3. **Visual Studio Code** — Download from [code.visualstudio.com](https://code.visualstudio.com/)
4. **Git** — Download from [git-scm.com](https://git-scm.com/)

### macOS Users

macOS includes a Unix-based operating system. To access the shell:

1. Open **Terminal** (found in Applications → Utilities) or
2. Install **iTerm2** for a more feature-rich terminal experience

### Linux Users

Linux systems include multiple terminal applications. Open your distribution's default terminal emulator, often called "Terminal" or "Console."

### Windows Users {#sec-windows-setup}

Windows requires additional setup to access a Unix-like environment. The recommended approach uses Windows Subsystem for Linux (WSL):

::: {.callout-caution title="Windows Users: Additional Steps Required"}
Follow these steps to install Ubuntu on Windows:

1. Run **Windows PowerShell** as administrator
2. Type `wsl --install` and press Enter
3. Restart your computer
4. Search for and install **Ubuntu** from the Microsoft Store, or type `wsl --install -d ubuntu` in PowerShell
5. Open Ubuntu and set up a username and password (doesn't need to match your Windows login)
6. Run `sudo apt update` followed by `sudo apt upgrade` to update packages
:::

A detailed guide is available at [ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-10](https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-10).

### Talapas Access

To use the university's computing cluster:

1. Ensure you're a member of a PIRG (Principal Investigator Research Group)
2. Your login credentials are your Duck ID and password
3. Off-campus access requires the UO VPN

We'll cover Talapas access in detail in @sec-hpc-talapas.

## Course Structure and Expectations

This book is designed to accompany a hands-on course where **most of class time is devoted to coding practice** rather than lectures. Expect to:

- Follow along with examples during class sessions
- Complete practice exercises to reinforce concepts
- Submit homework assignments demonstrating your skills
- Develop a final project applying what you've learned to your own research

::: {.callout-important title="Learning Takes Practice"}
Computational skills develop through repeated practice. Don't be discouraged if concepts don't click immediately—everyone struggles at first. The key is persistence and willingness to experiment.
:::

## Getting Help

When you encounter problems (and you will!), several resources are available:

**Manual Pages.** Unix commands have built-in documentation accessible via `man command_name`. Type `q` to exit.

**Help Functions.** In R, use `?function_name` or `help(function_name)` to access documentation.

**The Internet.** Sites like Stack Overflow contain solutions to virtually every common error message. Learning to search effectively is a crucial skill.

**Generative AI.** Tools like ChatGPT and Claude can explain concepts, debug code, and suggest solutions. However, always verify AI-generated code and understand what it does before using it.

![Discriminative models predict labels from features by learning decision boundaries, while generative models learn the underlying probability distributions of data to generate new content. Understanding this distinction helps you choose the right AI tool for your task.](images/ai_discriminative_vs_generative.png){#fig-discriminative-generative-ai width="80%"}

**Each Other.** Your classmates are experiencing the same learning curve. Collaboration and discussion accelerate everyone's learning.

## Summary

This chapter introduced the rationale for learning computational tools and provided an overview of the skills you'll develop. Key takeaways:

- Computational literacy is essential for modern biological research
- Scripting languages (Bash, R, Python) are ideal for data analysis
- Version control and reproducibility are professional best practices
- Learning requires patience, practice, and willingness to make mistakes

In the next chapter, we'll explore computer systems architecture to build your mental model of how computers work—knowledge that will inform everything that follows.

## Exercises {.unnumbered}

::: {.callout-tip title="Practice Exercises"}
1. **Environment Check**: Verify that you can open a terminal on your computer. What appears when you type `echo "Hello World"` and press Enter?

2. **Software Installation**: Install R and RStudio if you haven't already. Open RStudio and type `1 + 1` in the console. What happens?

3. **Reflection**: Write a paragraph describing one computational challenge in your current or planned research. What skills from this course might help address it?
:::
