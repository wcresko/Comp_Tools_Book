# Tidy Data Principles {#sec-tidy-data}

```{r}
#| label: setup
#| include: false
library(tidyverse)
library(gt)
theme_set(theme_minimal())
```

::: {.callout-note title="Learning Objectives"}
After completing this chapter, you will be able to:

- Define tidy data and explain its three principles
- Identify common problems in messy datasets
- Apply tidy data principles to your own data
- Distinguish between different data types
- Implement best practices for data organization
- Use appropriate file formats for data storage
- Use the tidyverse packages for data manipulation
- Apply dplyr verbs: filter, select, mutate, arrange, summarize
- Chain operations using the pipe operator
- Work with tibbles as modern data frames
:::

## Why Data Organization Matters

Before you can analyze data, you must organize it. The structure of your data profoundly affects how easily you can work with it. A well-organized dataset can be analyzed in minutes; a poorly organized one might require hours of preprocessing.

Consider this scenario: you've completed an experiment and collected data in a spreadsheet. Now you need to analyze it. If your data is organized consistently and logically, analysis is straightforward. If it's scattered across multiple tabs with inconsistent formatting, merged cells, and color-coded values, you're in for a frustrating experience.

**Tidy data** provides a standard way to organize data that makes analysis easier. It's not the only valid way to structure data, but it's particularly well-suited for analysis in R and Python.

## The Three Principles of Tidy Data

Hadley Wickham formalized the concept of tidy data in a influential paper [@wickham2014tidy]. Tidy data follows three rules:

::: {.callout-important title="The Three Rules of Tidy Data"}
1. Each **variable** forms a column
2. Each **observation** forms a row
3. Each **value** has its own cell
:::

Let's unpack what these mean.

### Variables as Columns

A **variable** is a characteristic that you measure, observe, or categorize. Examples:

- Gene expression level
- Treatment group
- Patient age
- Sample ID
- Measurement date

Each variable should have its own column with a descriptive header.

### Observations as Rows

An **observation** is a single unit of data collection—typically one measurement from one subject at one time point. Each observation gets its own row.

### Values in Cells

Each cell contains exactly one value. No merged cells, no multiple values crammed together, no implicit values indicated by color or formatting.

## Tidy vs. Messy Data: Examples

### A Tidy Dataset

```{r}
#| label: tbl-tidy-example
#| tbl-cap: "Example of tidy data organization"

tidy_data <- tibble(
  sample_id = c("S001", "S002", "S003", "S001", "S002", "S003"),
  timepoint = c("0h", "0h", "0h", "24h", "24h", "24h"),
  gene = rep("BRCA1", 6),
  expression = c(4.2, 3.8, 4.5, 8.1, 7.9, 9.2)
)

tidy_data |>
  gt() |>
  tab_header(title = "Gene Expression Data (Tidy Format)")
```

This is tidy because:

- Each column is a variable (sample_id, timepoint, gene, expression)
- Each row is an observation (one expression measurement)
- Each cell has one value

### A Messy Dataset (Same Data)

A common messy format spreads measurements across columns:

```{r}
#| label: tbl-messy-example
#| tbl-cap: "The same data in messy (wide) format"

messy_data <- tibble(
  sample_id = c("S001", "S002", "S003"),
  `BRCA1_0h` = c(4.2, 3.8, 4.5),
  `BRCA1_24h` = c(8.1, 7.9, 9.2)
)

messy_data |>
  gt() |>
  tab_header(title = "Gene Expression Data (Messy Format)")
```

This is messy because:

- Time point and gene are embedded in column names
- Each row represents multiple observations
- Adding genes or timepoints requires adding columns

### Why It Matters

With tidy data, operations are straightforward:

```{r}
#| label: tidy-operations

# Calculate mean expression by timepoint
tidy_data |>
  group_by(timepoint) |>
  summarize(mean_expression = mean(expression))

# Easy to filter and plot
tidy_data |>
  filter(timepoint == "24h")
```

With messy data, you must first reshape it—or write complex code to work around the structure.

## Common Data Problems

### Problem 1: Column Headers Are Values

Often, column names contain data values rather than variable names:

```{r}
#| label: headers-are-values

# Messy: years in column headers
population_messy <- tibble(
  country = c("USA", "Canada", "Mexico"),
  `2020` = c(331, 38, 129),
  `2021` = c(332, 38, 130),
  `2022` = c(333, 39, 131)
)

population_messy |> gt()
```

Solution: "Pivot" the data to create a `year` column:

```{r}
#| label: pivot-longer

population_tidy <- population_messy |>
  pivot_longer(
    cols = `2020`:`2022`,
    names_to = "year",
    values_to = "population"
  )

population_tidy |> gt()
```

### Problem 2: Multiple Variables in One Column

Sometimes multiple pieces of information are crammed into one cell:

```{r}
#| label: multiple-vars

# Messy: rate contains both values
messy_rates <- tibble(
  country = c("USA", "Canada", "Mexico"),
  rate = c("1000/50000", "200/10000", "500/25000")
)

messy_rates |> gt()
```

Solution: Separate into distinct columns:

```{r}
#| label: separate-cols

tidy_rates <- messy_rates |>
  separate(rate, into = c("cases", "population"), sep = "/", convert = TRUE)

tidy_rates |> gt()
```

### Problem 3: Variables in Both Rows and Columns

Complex tables sometimes mix variables across dimensions:

```{r}
#| label: both-dimensions

# Messy: measurement type in rows, conditions in columns
messy_experiment <- tibble(
  measurement = c("weight", "height", "weight", "height"),
  subject = c("A", "A", "B", "B"),
  control = c(70, 170, 65, 165),
  treatment = c(68, 170, 64, 166)
)

messy_experiment |> gt()
```

This requires multiple steps to tidy: pivot longer, then pivot wider.

### Problem 4: Multiple Observational Units

When a single table contains data about different types of things:

```{r}
#| label: multiple-units

# Messy: patient and hospital info in same table
combined_data <- tibble(
  patient_id = c("P001", "P002"),
  patient_name = c("Alice", "Bob"),
  hospital_id = c("H1", "H1"),
  hospital_name = c("General", "General"),
  hospital_beds = c(500, 500),  # Repeated!
  diagnosis = c("Flu", "Cold")
)

combined_data |> gt()
```

Solution: Normalize into separate tables linked by keys.

## Best Practices for Data Organization

### Naming Conventions

::: {.callout-tip title="Data File Naming Rules"}
**File names:**

- Use descriptive names: `patient_outcomes_2024.csv`
- Include dates in ISO format: `YYYY-MM-DD`
- Avoid spaces (use underscores or hyphens)
- Keep names concise but informative

**Column names:**

- Use lowercase with underscores: `sample_id`, `gene_expression`
- Make names meaningful: `treatment_group` not `tg`
- Avoid special characters and spaces
- Start with a letter, not a number
:::

### File Formats

| Format | Extension | Best For |
|:-------|:----------|:---------|
| Comma-separated | `.csv` | General tabular data |
| Tab-separated | `.tsv` | Data containing commas |
| Plain text | `.txt` | Simple data, scripts |
| Excel | `.xlsx` | Sharing with non-programmers |
| RDS | `.rds` | R-specific data with types preserved |
| Parquet | `.parquet` | Large datasets, fast reading |

: Common data file formats {#tbl-file-formats}

For long-term storage and sharing, prefer plain text formats (CSV, TSV) over proprietary formats. They're human-readable and don't require specific software.

### Documentation

Always create a **data dictionary** (also called a codebook) documenting:

- Variable names and descriptions
- Units of measurement
- Allowable values or categories
- Coding of missing values
- Source of the data
- Date created/modified

### Preserving Raw Data

::: {.callout-warning title="Never Modify Raw Data"}
Always keep an unchanged copy of your original data. Create a separate processed version for analysis. This allows you to:

- Retrace your steps if something goes wrong
- Rerun analysis with different preprocessing
- Share the original data with collaborators
:::

## Data Types

Understanding data types helps you organize and analyze correctly.

### Categorical vs. Quantitative

```{r}
#| label: tbl-data-types-table
#| tbl-cap: "Classification of data types"

data_types <- tibble(
  Category = c("Categorical", "Categorical", "Quantitative", "Quantitative"),
  Type = c("Ordinal", "Nominal", "Ratio", "Interval"),
  Description = c(
    "Ordered categories",
    "Unordered categories",
    "True zero, ratios meaningful",
    "No true zero"
  ),
  Examples = c(
    "small, medium, large",
    "red, blue, green",
    "height, weight, concentration",
    "temperature (°C), calendar year"
  )
)

data_types |>
  gt() |>
  tab_header(title = "Data Type Classification")
```

### R Data Types

R has specific data types for these categories:

```{r}
#| label: r-types

# Numeric (continuous)
temperature <- c(37.2, 36.8, 38.1)
class(temperature)

# Integer
counts <- c(1L, 2L, 3L)
class(counts)

# Character
sample_names <- c("control", "treatment", "treatment")
class(sample_names)

# Factor (categorical)
treatment <- factor(c("low", "medium", "high"), 
                   levels = c("low", "medium", "high"),
                   ordered = TRUE)
class(treatment)
treatment

# Logical
passed_qc <- c(TRUE, TRUE, FALSE)
class(passed_qc)
```

### When to Use Factors

Factors are R's way of handling categorical variables. Use them when:

- You have a limited set of possible values
- The order matters (ordinal data)
- You want specific grouping in analyses and plots

```{r}
#| label: factor-example

# Character vector sorts alphabetically
treatments <- c("High", "Low", "Medium", "Low", "High")
sort(treatments)

# Factor maintains meaningful order
treatments_factor <- factor(treatments, 
                           levels = c("Low", "Medium", "High"))
sort(treatments_factor)
```

## Structuring Spreadsheets for Analysis

If you must use spreadsheets for data entry, follow these guidelines:

::: {.callout-important title="Spreadsheet Best Practices"}
1. **One header row only** — Put variable names in row 1
2. **No merged cells** — They break data structure
3. **No color-coding as data** — Use a column instead
4. **Consistent missing values** — Use `NA`, not blank, `-`, or `N/A`
5. **One sheet per dataset** — Don't spread data across tabs
6. **Export as CSV** — Preserve as plain text
7. **No calculations in raw data** — Keep raw and calculated data separate
:::

### Before and After

**Bad spreadsheet practices:**

- Merged cells for visual grouping
- Color-coded cells indicating categories
- Multiple header rows
- Notes in random cells
- Mixed data types in columns
- Embedded calculations

**Good spreadsheet practices:**

- Clean rectangular data
- Single header row
- Consistent formatting throughout
- Separate documentation sheet
- Explicit coding of all information

## The Tidyverse: A Collection of Data Science Packages

The **tidyverse** is a collection of R packages designed for data science that share a common philosophy and work seamlessly together. These packages make data manipulation, visualization, and analysis more intuitive and readable.

### Core Tidyverse Packages

| Package | Purpose |
|:--------|:--------|
| **dplyr** | Data manipulation (filter, select, mutate, etc.) |
| **ggplot2** | Data visualization |
| **tidyr** | Data tidying (pivot, separate, etc.) |
| **readr** | Fast data import |
| **purrr** | Functional programming |
| **stringr** | String manipulation |
| **forcats** | Working with factors |
| **tibble** | Modern data frames |

: Core tidyverse packages {#tbl-tidyverse}

Load all core packages at once:

```{r}
#| label: load-tidyverse
#| eval: false

library(tidyverse)
```

## The Pipe Operator

One of the most powerful features of the tidyverse is the **pipe operator**, which allows you to chain operations together in a readable way.

### The Native Pipe: `|>`

R 4.1+ includes a native pipe operator `|>`:

```{r}
#| label: native-pipe

# Without pipe: nested, hard to read
sqrt(sum(abs(c(-4, 9, -16))))

# With pipe: reads left to right
c(-4, 9, -16) |>
  abs() |>
  sum() |>
  sqrt()
```

### The magrittr Pipe: `%>%`

The tidyverse also provides `%>%` from the magrittr package, which has additional features:

```{r}
#| label: magrittr-pipe

library(dplyr)

# Both work similarly for most cases
c(1, 2, 3, 4, 5) |> mean()
c(1, 2, 3, 4, 5) %>% mean()
```

::: {.callout-tip}
The pipe transforms `x |> f(y)` into `f(x, y)`. Think of it as "take this, then do that." This makes code read like a recipe: take data, then filter, then select, then summarize.
:::

## Data Manipulation with dplyr

The **dplyr** package provides a consistent set of "verbs" for data manipulation. These functions are designed to be intuitive and compose well together.

### The Five Core dplyr Verbs

| Verb | Action |
|:-----|:-------|
| `filter()` | Pick rows based on conditions |
| `select()` | Pick columns by name |
| `arrange()` | Reorder rows |
| `mutate()` | Create or modify columns |
| `summarize()` | Reduce to summary statistics |

: The five core dplyr verbs {#tbl-dplyr-verbs}

Let's create sample data to demonstrate these:

```{r}
#| label: sample-data

# Sample experimental data
experiments <- tibble(
  sample_id = paste0("S", 1:12),
  treatment = rep(c("control", "drug_A", "drug_B"), each = 4),
  replicate = rep(1:4, 3),
  expression = c(10.2, 11.1, 9.8, 10.5,   # control
                 15.3, 14.8, 16.2, 15.0,   # drug_A
                 18.1, 19.2, 17.5, 18.8),  # drug_B
  cell_count = c(1000, 1050, 980, 1020,
                 1100, 1080, 1150, 1090,
                 1200, 1250, 1180, 1220)
)

experiments
```

### Filtering Rows with `filter()`

Select rows that meet specific conditions:

```{r}
#| label: filter-examples

# Single condition
experiments |>
  filter(treatment == "drug_A")

# Multiple conditions (AND)
experiments |>
  filter(treatment == "drug_A", expression > 15)

# OR conditions
experiments |>
  filter(treatment == "drug_A" | treatment == "drug_B")

# Using %in% for multiple values
experiments |>
  filter(treatment %in% c("drug_A", "drug_B"))
```

### Selecting Columns with `select()`

Choose which columns to keep:

```{r}
#| label: select-examples

# Select specific columns
experiments |>
  select(sample_id, treatment, expression)

# Select range of columns
experiments |>
  select(sample_id:replicate)

# Exclude columns with minus
experiments |>
  select(-cell_count)

# Select using helper functions
experiments |>
  select(starts_with("exp"))

experiments |>
  select(where(is.numeric))
```

### Arranging Rows with `arrange()`

Sort data by one or more columns:
```{r}
#| label: arrange-examples

# Ascending order (default)
experiments |>
  arrange(expression)

# Descending order
experiments |>
  arrange(desc(expression))

# Multiple columns
experiments |>
  arrange(treatment, desc(expression))
```

### Creating Columns with `mutate()`

Add new columns or modify existing ones:

```{r}
#| label: mutate-examples

experiments |>
  mutate(
    # Create new columns
    log_expression = log2(expression),
    expression_per_cell = expression / cell_count * 1000,
    # Modify existing
    treatment = toupper(treatment)
  )
```

### Summarizing Data with `summarize()`

Collapse multiple rows into summary statistics:

```{r}
#| label: summarize-examples

experiments |>
  summarize(
    mean_expression = mean(expression),
    sd_expression = sd(expression),
    n_samples = n()
  )
```

### Grouping with `group_by()`

The real power of `summarize()` comes with `group_by()`:

```{r}
#| label: group-by-examples

# Summary statistics by treatment
experiments |>
  group_by(treatment) |>
  summarize(
    mean_expression = mean(expression),
    sd_expression = sd(expression),
    n = n()
  )

# Multiple grouping variables
experiments |>
  group_by(treatment) |>
  summarize(
    mean_expr = mean(expression),
    max_expr = max(expression),
    min_expr = min(expression)
  ) |>
  arrange(desc(mean_expr))
```

### Chaining Operations Together

The power of dplyr shines when chaining multiple operations:

```{r}
#| label: chaining-example

experiments |>
  filter(treatment != "control") |>           # Remove controls
  mutate(log_expr = log2(expression)) |>      # Log transform
  group_by(treatment) |>                       # Group by treatment
  summarize(
    mean_log_expr = mean(log_expr),
    se = sd(log_expr) / sqrt(n())
  ) |>
  arrange(desc(mean_log_expr))                 # Sort by mean
```

## Tibbles: Modern Data Frames

**Tibbles** are the tidyverse's enhanced version of data frames. They have several advantages:

### Creating Tibbles

```{r}
#| label: create-tibble

# Create a tibble
my_tibble <- tibble(
  x = 1:5,
  y = x^2,  # Can reference earlier columns
  z = c("a", "b", "c", "d", "e")
)

my_tibble

# Convert data frame to tibble
as_tibble(mtcars) |> head()
```

### Tibble Advantages

1. **Better printing**: Shows first 10 rows and fits columns to screen
2. **No partial matching**: `df$col` won't match `df$column`
3. **No string-to-factor conversion**: Characters stay as characters
4. **Preserves column types**: Subsetting always returns a tibble

```{r}
#| label: tibble-advantages

# Data frame subsetting can surprise you
df <- data.frame(x = 1:3, y = 4:6)
class(df[, 1])  # Returns vector!

# Tibble subsetting is consistent
tb <- tibble(x = 1:3, y = 4:6)
class(tb[, 1])  # Returns tibble
```

## Additional dplyr Functions

### Conditional Logic with `case_when()`

```{r}
#| label: case-when

experiments |>
  mutate(
    expression_level = case_when(
      expression < 12 ~ "low",
      expression < 17 ~ "medium",
      TRUE ~ "high"
    )
  )
```

### Counting with `count()`

```{r}
#| label: count-example

experiments |>
  count(treatment)

experiments |>
  count(treatment, sort = TRUE)
```

### Distinct Values with `distinct()`

```{r}
#| label: distinct-example

experiments |>
  distinct(treatment)
```

### Renaming with `rename()`

```{r}
#| label: rename-example

experiments |>
  rename(expr = expression, cells = cell_count)
```

## Summary

Tidy data provides a consistent structure that simplifies analysis:

- Each variable is a column
- Each observation is a row
- Each value occupies one cell

Key principles for data organization:

- Use descriptive, consistent naming conventions
- Document your data with a data dictionary
- Preserve raw data separately from processed data
- Choose appropriate file formats for your needs
- Understand the difference between data types

The tidyverse provides powerful tools for working with tidy data:

- The **pipe operator** (`|>` or `%>%`) chains operations for readable code
- **dplyr verbs** provide intuitive data manipulation:
  - `filter()` selects rows by condition
  - `select()` picks columns by name
  - `mutate()` creates or modifies columns
  - `arrange()` sorts rows
  - `summarize()` computes summary statistics
  - `group_by()` enables grouped operations
- **Tibbles** are enhanced data frames with consistent behavior
- Functions like `case_when()`, `count()`, and `distinct()` handle common tasks

These practices and tools apply across data science workflows. Well-organized data combined with tidyverse tools makes analysis efficient, reproducible, and shareable.

## Exercises {.unnumbered}

::: {.callout-tip title="Practice Exercises"}
**Exercise 1: Identify Tidy Data**

For each dataset description, determine if it's tidy. If not, explain what violates tidy principles:

1. Patient data with columns: patient_id, age, blood_pressure_systolic, blood_pressure_diastolic
2. Gene expression with columns: gene_name, sample_1, sample_2, sample_3
3. Survey data with columns: respondent_id, question, response
4. Weather data with columns: city, 2023_temp, 2024_temp, 2023_precip, 2024_precip

**Exercise 2: Reshape Data**

Given this messy dataset:
```
Country   1990   2000   2010
USA       250    280    310  
Canada    27     31     35
Mexico    86     100    120
```

Write R code using `pivot_longer()` to convert it to tidy format.

**Exercise 3: Data Dictionary**

Create a data dictionary for an experiment tracking:
- Gene expression levels measured at 0, 12, and 24 hours
- Three treatment groups (control, low dose, high dose)
- Twenty biological replicates per group
- Quality control pass/fail flags

**Exercise 4: Spot the Problems**

Review a dataset you've worked with (or your lab's data). Identify any violations of tidy data principles and propose solutions.

**Exercise 5: dplyr Practice**

Using the built-in `mtcars` dataset:
1. Filter to only cars with 6 or 8 cylinders
2. Select only the columns `mpg`, `cyl`, `hp`, and `wt`
3. Create a new column `hp_per_cyl` (horsepower per cylinder)
4. Arrange by `mpg` in descending order

**Exercise 6: Grouped Summaries**

Using the `iris` dataset:
1. Calculate the mean and standard deviation of `Sepal.Length` for each `Species`
2. Find the maximum `Petal.Width` for each species
3. Count the number of observations per species
4. Chain all these operations using the pipe operator

**Exercise 7: Data Transformation Pipeline**

Create a complete analysis pipeline that:
1. Starts with the `mtcars` dataset
2. Filters to automatic transmission cars (`am == 0`)
3. Groups by number of cylinders
4. Calculates mean mpg, mean horsepower, and count per group
5. Creates a new column classifying fuel efficiency as "good" (mpg >= 20) or "poor"
6. Arranges by mean mpg descending

**Exercise 8: Tibble Exploration**

1. Convert `mtcars` to a tibble
2. Compare how the data frame and tibble display when printed
3. Test subsetting behavior: what class does `mtcars[, 1]` return vs `as_tibble(mtcars)[, 1]`?
:::
